{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import voyageai\n",
    "from typing import List, Dict, Any\n",
    "from tqdm import tqdm\n",
    "from inference_adapter import InferenceAdapter\n",
    "\n",
    "class ContextualVectorDB:\n",
    "    def __init__(self, name: str):\n",
    "        self.openai_client = InferenceAdapter()\n",
    "        self.voyage_client = voyageai.Client()\n",
    "        self.name = name\n",
    "        self.embeddings = []\n",
    "        self.metadata = []\n",
    "        self.query_cache = {}\n",
    "        self.db_path = f\"./data/{name}/contextual_vector_db.pkl\"\n",
    "\n",
    "        self.token_counts = {\n",
    "            'input': 0,\n",
    "            'output': 0,\n",
    "            'cache_read': 0,\n",
    "            'non_cached': 0\n",
    "        }\n",
    "\n",
    "    async def situate_context(self, doc: str, chunk: str) -> tuple[str, Any]:\n",
    "        from pydantic import BaseModel, Field\n",
    "\n",
    "        class ContextResponse(BaseModel):\n",
    "            context: str = Field(..., description=\"The succinct context for the chunk\")\n",
    "\n",
    "        DOCUMENT_CONTEXT_PROMPT = \"\"\"\n",
    "        <document>\n",
    "        {doc_content}\n",
    "        </document>\n",
    "        \"\"\"\n",
    "\n",
    "        CHUNK_CONTEXT_PROMPT = \"\"\"\n",
    "        Here is the chunk we want to situate within the whole document\n",
    "        <chunk>\n",
    "        {chunk_content}\n",
    "        </chunk>\n",
    "\n",
    "        Please give a short succinct context to situate this chunk within the overall document for the purposes of improving search retrieval of the chunk.\n",
    "        Answer only with the succinct context and nothing else.\n",
    "        \"\"\"\n",
    "\n",
    "        return await self.openai_client.predict_with_parse_async(\n",
    "            {\n",
    "                \"model\": \"gpt-4o-2024-08-06\",\n",
    "                \"temperature\": 0,\n",
    "            },\n",
    "            response_format=ContextResponse,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": DOCUMENT_CONTEXT_PROMPT.format(doc_content=doc)\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": CHUNK_CONTEXT_PROMPT.format(chunk_content=chunk)\n",
    "                },\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    async def load_data(self, dataset: List[Dict[str, Any]]):\n",
    "        if self.embeddings and self.metadata:\n",
    "            print(\"Vector database is already loaded. Skipping data loading.\")\n",
    "            return\n",
    "        if os.path.exists(self.db_path):\n",
    "            print(\"Loading vector database from disk.\")\n",
    "            self.load_db()\n",
    "            return\n",
    "\n",
    "        texts_to_embed = []\n",
    "        metadata = []\n",
    "        total_chunks = sum(len(doc['chunks']) for doc in dataset)\n",
    "\n",
    "        async def process_chunk(doc, chunk):\n",
    "            #for each chunk, produce the context\n",
    "            contextualized_text, usage = await self.situate_context(doc['content'], chunk['content'])\n",
    "            print(usage)\n",
    "            self.token_counts['input'] += usage.prompt_tokens\n",
    "            self.token_counts['output'] += usage.completion_tokens\n",
    "            self.token_counts['cache_read'] += usage.prompt_tokens_details.get('cached_tokens', 0)\n",
    "            self.token_counts['non_cached'] += usage.prompt_tokens - usage.prompt_tokens_details.get('cached_tokens', 0)\n",
    "\n",
    "            return {\n",
    "                #append the context to the original text chunk\n",
    "                'text_to_embed': f\"{chunk['content']}\\n\\n{contextualized_text.context}\",\n",
    "                'metadata': {\n",
    "                    'doc_id': doc['doc_id'],\n",
    "                    'original_uuid': doc['original_uuid'],\n",
    "                    'chunk_id': chunk['chunk_id'],\n",
    "                    'original_index': chunk['original_index'],\n",
    "                    'original_content': chunk['content'],\n",
    "                    'contextualized_content': contextualized_text.context\n",
    "                }\n",
    "            }\n",
    "\n",
    "        print(f\"Processing {total_chunks} chunks sequentially\")\n",
    "        for doc in tqdm(dataset[:], desc=\"Processing documents\"):\n",
    "            for chunk in doc['chunks']:\n",
    "                result = await process_chunk(doc, chunk)\n",
    "                print(result)\n",
    "                texts_to_embed.append(result['text_to_embed'])\n",
    "                metadata.append(result['metadata'])\n",
    "\n",
    "        self._embed_and_store(texts_to_embed, metadata)\n",
    "        self.save_db()\n",
    "\n",
    "        #logging token usage\n",
    "        print(f\"Contextual Vector database loaded and saved. Total chunks processed: {len(texts_to_embed)}\")\n",
    "        print(f\"Total input tokens without caching: {self.token_counts['non_cached']}\")\n",
    "        print(f\"Total output tokens: {self.token_counts['output']}\")\n",
    "        print(f\"Total input tokens read from cache: {self.token_counts['cache_read']}\")\n",
    "        \n",
    "        total_tokens = self.token_counts['input'] + self.token_counts['output']\n",
    "        savings_percentage = (self.token_counts['cache_read'] / total_tokens) * 100 if total_tokens > 0 else 0\n",
    "        print(f\"Total input token savings from prompt caching: {savings_percentage:.2f}% of all input tokens used were read from cache.\")\n",
    "\n",
    "    #we use voyage AI here for embeddings. Read more here: https://docs.voyageai.com/docs/embeddings\n",
    "    def _embed_and_store(self, texts: List[str], data: List[Dict[str, Any]]):\n",
    "        batch_size = 128\n",
    "        result = [\n",
    "            self.voyage_client.embed(\n",
    "                texts[i : i + batch_size],\n",
    "                model=\"voyage-2\"\n",
    "            ).embeddings\n",
    "            for i in range(0, len(texts), batch_size)\n",
    "        ]\n",
    "        self.embeddings = [embedding for batch in result for embedding in batch]\n",
    "        self.metadata = data\n",
    "\n",
    "    def search(self, query: str, k: int = 20) -> List[Dict[str, Any]]:\n",
    "        if query in self.query_cache:\n",
    "            query_embedding = self.query_cache[query]\n",
    "        else:\n",
    "            query_embedding = self.voyage_client.embed([query], model=\"voyage-2\").embeddings[0]\n",
    "            self.query_cache[query] = query_embedding\n",
    "\n",
    "        if not self.embeddings:\n",
    "            raise ValueError(\"No data loaded in the vector database.\")\n",
    "\n",
    "        similarities = np.dot(self.embeddings, query_embedding)\n",
    "        top_indices = np.argsort(similarities)[::-1][:k]\n",
    "        \n",
    "        top_results = []\n",
    "        for idx in top_indices:\n",
    "            result = {\n",
    "                \"metadata\": self.metadata[idx],\n",
    "                \"similarity\": float(similarities[idx]),\n",
    "            }\n",
    "            top_results.append(result)\n",
    "        return top_results\n",
    "\n",
    "    def save_db(self):\n",
    "        data = {\n",
    "            \"embeddings\": self.embeddings,\n",
    "            \"metadata\": self.metadata,\n",
    "            \"query_cache\": json.dumps(self.query_cache),\n",
    "        }\n",
    "        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)\n",
    "        with open(self.db_path, \"wb\") as file:\n",
    "            pickle.dump(data, file)\n",
    "\n",
    "    def load_db(self):\n",
    "        if not os.path.exists(self.db_path):\n",
    "            raise ValueError(\"Vector database file not found. Use load_data to create a new database.\")\n",
    "        with open(self.db_path, \"rb\") as file:\n",
    "            data = pickle.load(file)\n",
    "        self.embeddings = data[\"embeddings\"]\n",
    "        self.metadata = data[\"metadata\"]\n",
    "        self.query_cache = json.loads(data[\"query_cache\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 20 chunks sequentially\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletionUsage(completion_tokens=46, prompt_tokens=2567, total_tokens=2613, prompt_tokens_details={'cached_tokens': 2176}, completion_tokens_details={'reasoning_tokens': 0})\n",
      "{'text_to_embed': '//! Executor for differential fuzzing.\\n//! It wraps two executors that will be run after each other with the same input.\\n//! In comparison to the [`crate::executors::CombinedExecutor`] it also runs the secondary executor in `run_target`.\\n//!\\nuse core::{cell::UnsafeCell, fmt::Debug, ptr};\\n\\nuse libafl_bolts::{ownedref::OwnedMutPtr, tuples::MatchName};\\nuse serde::{Deserialize, Serialize};\\n\\nuse crate::{\\n    executors::{Executor, ExitKind, HasObservers},\\n    inputs::UsesInput,\\n    observers::{DifferentialObserversTuple, ObserversTuple, UsesObservers},\\n    state::UsesState,\\n    Error,\\n};\\n\\n/// A [`DiffExecutor`] wraps a primary executor, forwarding its methods, and a secondary one\\n#[derive(Debug)]\\npub struct DiffExecutor<A, B, OTA, OTB, DOT> {\\n    primary: A,\\n    secondary: B,\\n    observers: UnsafeCell<ProxyObserversTuple<OTA, OTB, DOT>>,\\n}\\n\\n\\n\\nThis chunk introduces the `DiffExecutor` struct, which is designed for differential fuzzing by wrapping two executors to run sequentially with the same input, and includes necessary imports and trait implementations for its functionality.', 'metadata': {'doc_id': 'doc_1', 'original_uuid': '5e4c01057a10732d34784af2a97bee9d173863f043b9901de8ef7f57bc590145', 'chunk_id': 'doc_1_chunk_0', 'original_index': 0, 'original_content': '//! Executor for differential fuzzing.\\n//! It wraps two executors that will be run after each other with the same input.\\n//! In comparison to the [`crate::executors::CombinedExecutor`] it also runs the secondary executor in `run_target`.\\n//!\\nuse core::{cell::UnsafeCell, fmt::Debug, ptr};\\n\\nuse libafl_bolts::{ownedref::OwnedMutPtr, tuples::MatchName};\\nuse serde::{Deserialize, Serialize};\\n\\nuse crate::{\\n    executors::{Executor, ExitKind, HasObservers},\\n    inputs::UsesInput,\\n    observers::{DifferentialObserversTuple, ObserversTuple, UsesObservers},\\n    state::UsesState,\\n    Error,\\n};\\n\\n/// A [`DiffExecutor`] wraps a primary executor, forwarding its methods, and a secondary one\\n#[derive(Debug)]\\npub struct DiffExecutor<A, B, OTA, OTB, DOT> {\\n    primary: A,\\n    secondary: B,\\n    observers: UnsafeCell<ProxyObserversTuple<OTA, OTB, DOT>>,\\n}\\n\\n', 'contextualized_content': 'This chunk introduces the `DiffExecutor` struct, which is designed for differential fuzzing by wrapping two executors to run sequentially with the same input, and includes necessary imports and trait implementations for its functionality.'}}\n",
      "CompletionUsage(completion_tokens=63, prompt_tokens=2554, total_tokens=2617, prompt_tokens_details={'cached_tokens': 2176}, completion_tokens_details={'reasoning_tokens': 0})\n",
      "{'text_to_embed': 'impl<A, B, OTA, OTB, DOT> DiffExecutor<A, B, OTA, OTB, DOT> {\\n    /// Create a new `DiffExecutor`, wrapping the given `executor`s.\\n    pub fn new(primary: A, secondary: B, observers: DOT) -> Self\\n    where\\n        A: UsesState + HasObservers<Observers = OTA>,\\n        B: UsesState<State = A::State> + HasObservers<Observers = OTB>,\\n        DOT: DifferentialObserversTuple<OTA, OTB, A::State>,\\n        OTA: ObserversTuple<A::State>,\\n        OTB: ObserversTuple<A::State>,\\n    {\\n        Self {\\n            primary,\\n            secondary,\\n            observers: UnsafeCell::new(ProxyObserversTuple {\\n                primary: OwnedMutPtr::Ptr(ptr::null_mut()),\\n                secondary: OwnedMutPtr::Ptr(ptr::null_mut()),\\n                differential: observers,\\n            }),\\n        }\\n    }\\n\\n\\n\\nThe chunk defines the constructor for the `DiffExecutor` struct, which initializes a new instance by wrapping two executors (primary and secondary) and a set of differential observers. It specifies the trait bounds required for the executors and observers, ensuring compatibility and functionality within the differential fuzzing framework.', 'metadata': {'doc_id': 'doc_1', 'original_uuid': '5e4c01057a10732d34784af2a97bee9d173863f043b9901de8ef7f57bc590145', 'chunk_id': 'doc_1_chunk_1', 'original_index': 1, 'original_content': 'impl<A, B, OTA, OTB, DOT> DiffExecutor<A, B, OTA, OTB, DOT> {\\n    /// Create a new `DiffExecutor`, wrapping the given `executor`s.\\n    pub fn new(primary: A, secondary: B, observers: DOT) -> Self\\n    where\\n        A: UsesState + HasObservers<Observers = OTA>,\\n        B: UsesState<State = A::State> + HasObservers<Observers = OTB>,\\n        DOT: DifferentialObserversTuple<OTA, OTB, A::State>,\\n        OTA: ObserversTuple<A::State>,\\n        OTB: ObserversTuple<A::State>,\\n    {\\n        Self {\\n            primary,\\n            secondary,\\n            observers: UnsafeCell::new(ProxyObserversTuple {\\n                primary: OwnedMutPtr::Ptr(ptr::null_mut()),\\n                secondary: OwnedMutPtr::Ptr(ptr::null_mut()),\\n                differential: observers,\\n            }),\\n        }\\n    }\\n\\n', 'contextualized_content': 'The chunk defines the constructor for the `DiffExecutor` struct, which initializes a new instance by wrapping two executors (primary and secondary) and a set of differential observers. It specifies the trait bounds required for the executors and observers, ensuring compatibility and functionality within the differential fuzzing framework.'}}\n",
      "CompletionUsage(completion_tokens=49, prompt_tokens=2627, total_tokens=2676, prompt_tokens_details={'cached_tokens': 2176}, completion_tokens_details={'reasoning_tokens': 0})\n",
      "{'text_to_embed': '    /// Retrieve the primary `Executor` that is wrapped by this `DiffExecutor`.\\n    pub fn primary(&mut self) -> &mut A {\\n        &mut self.primary\\n    }\\n\\n    /// Retrieve the secondary `Executor` that is wrapped by this `DiffExecutor`.\\n    pub fn secondary(&mut self) -> &mut B {\\n        &mut self.secondary\\n    }\\n}\\n\\nimpl<A, B, EM, DOT, Z> Executor<EM, Z> for DiffExecutor<A, B, A::Observers, B::Observers, DOT>\\nwhere\\n    A: Executor<EM, Z> + HasObservers,\\n    B: Executor<EM, Z, State = A::State> + HasObservers,\\n    EM: UsesState<State = A::State>,\\n    DOT: DifferentialObserversTuple<A::Observers, B::Observers, A::State>,\\n    Z: UsesState<State = A::State>,\\n{\\n    fn run_target(\\n        &mut self,\\n        fuzzer: &mut Z,\\n        state: &mut Self::State,\\n        mgr: &mut EM,\\n        input: &Self::Input,\\n    ) -> Result<ExitKind, Error> {\\n        self.observers(); // update in advance\\n        let observers = self.observers.get_mut();\\n        observers\\n            .differential\\n\\n\\nThis chunk is part of the `DiffExecutor` implementation, focusing on methods to access the primary and secondary executors and the `run_target` function, which executes both executors with the same input and compares their results.', 'metadata': {'doc_id': 'doc_1', 'original_uuid': '5e4c01057a10732d34784af2a97bee9d173863f043b9901de8ef7f57bc590145', 'chunk_id': 'doc_1_chunk_2', 'original_index': 2, 'original_content': '    /// Retrieve the primary `Executor` that is wrapped by this `DiffExecutor`.\\n    pub fn primary(&mut self) -> &mut A {\\n        &mut self.primary\\n    }\\n\\n    /// Retrieve the secondary `Executor` that is wrapped by this `DiffExecutor`.\\n    pub fn secondary(&mut self) -> &mut B {\\n        &mut self.secondary\\n    }\\n}\\n\\nimpl<A, B, EM, DOT, Z> Executor<EM, Z> for DiffExecutor<A, B, A::Observers, B::Observers, DOT>\\nwhere\\n    A: Executor<EM, Z> + HasObservers,\\n    B: Executor<EM, Z, State = A::State> + HasObservers,\\n    EM: UsesState<State = A::State>,\\n    DOT: DifferentialObserversTuple<A::Observers, B::Observers, A::State>,\\n    Z: UsesState<State = A::State>,\\n{\\n    fn run_target(\\n        &mut self,\\n        fuzzer: &mut Z,\\n        state: &mut Self::State,\\n        mgr: &mut EM,\\n        input: &Self::Input,\\n    ) -> Result<ExitKind, Error> {\\n        self.observers(); // update in advance\\n        let observers = self.observers.get_mut();\\n        observers\\n            .differential\\n', 'contextualized_content': 'This chunk is part of the `DiffExecutor` implementation, focusing on methods to access the primary and secondary executors and the `run_target` function, which executes both executors with the same input and compares their results.'}}\n",
      "CompletionUsage(completion_tokens=44, prompt_tokens=2461, total_tokens=2505, prompt_tokens_details={'cached_tokens': 2304}, completion_tokens_details={'reasoning_tokens': 0})\n",
      "{'text_to_embed': '            .pre_observe_first_all(observers.primary.as_mut())?;\\n        observers.primary.as_mut().pre_exec_all(state, input)?;\\n        let ret1 = self.primary.run_target(fuzzer, state, mgr, input)?;\\n        observers\\n            .primary\\n            .as_mut()\\n            .post_exec_all(state, input, &ret1)?;\\n        observers\\n            .differential\\n            .post_observe_first_all(observers.primary.as_mut())?;\\n        observers\\n            .differential\\n\\n\\nThis chunk is part of the `run_target` method in the `DiffExecutor` struct, which executes the primary executor with the given input, updates observers, and checks for differences in execution results.', 'metadata': {'doc_id': 'doc_1', 'original_uuid': '5e4c01057a10732d34784af2a97bee9d173863f043b9901de8ef7f57bc590145', 'chunk_id': 'doc_1_chunk_3', 'original_index': 3, 'original_content': '            .pre_observe_first_all(observers.primary.as_mut())?;\\n        observers.primary.as_mut().pre_exec_all(state, input)?;\\n        let ret1 = self.primary.run_target(fuzzer, state, mgr, input)?;\\n        observers\\n            .primary\\n            .as_mut()\\n            .post_exec_all(state, input, &ret1)?;\\n        observers\\n            .differential\\n            .post_observe_first_all(observers.primary.as_mut())?;\\n        observers\\n            .differential\\n', 'contextualized_content': 'This chunk is part of the `run_target` method in the `DiffExecutor` struct, which executes the primary executor with the given input, updates observers, and checks for differences in execution results.'}}\n",
      "CompletionUsage(completion_tokens=50, prompt_tokens=2509, total_tokens=2559, prompt_tokens_details={'cached_tokens': 2304}, completion_tokens_details={'reasoning_tokens': 0})\n",
      "{'text_to_embed': '            .pre_observe_second_all(observers.secondary.as_mut())?;\\n        observers.secondary.as_mut().pre_exec_all(state, input)?;\\n        let ret2 = self.secondary.run_target(fuzzer, state, mgr, input)?;\\n        observers\\n            .secondary\\n            .as_mut()\\n            .post_exec_all(state, input, &ret2)?;\\n        observers\\n            .differential\\n            .post_observe_second_all(observers.secondary.as_mut())?;\\n        if ret1 == ret2 {\\n            Ok(ret1)\\n        } else {\\n            // We found a diff in the exit codes!\\n            Ok(ExitKind::Diff {\\n                primary: ret1.into(),\\n                secondary: ret2.into(),\\n            })\\n        }\\n    }\\n}\\n\\n\\n\\nThis chunk is part of the `run_target` method implementation in the `DiffExecutor` struct, which executes two wrapped executors sequentially with the same input, compares their exit results, and identifies any differences in their behavior.', 'metadata': {'doc_id': 'doc_1', 'original_uuid': '5e4c01057a10732d34784af2a97bee9d173863f043b9901de8ef7f57bc590145', 'chunk_id': 'doc_1_chunk_4', 'original_index': 4, 'original_content': '            .pre_observe_second_all(observers.secondary.as_mut())?;\\n        observers.secondary.as_mut().pre_exec_all(state, input)?;\\n        let ret2 = self.secondary.run_target(fuzzer, state, mgr, input)?;\\n        observers\\n            .secondary\\n            .as_mut()\\n            .post_exec_all(state, input, &ret2)?;\\n        observers\\n            .differential\\n            .post_observe_second_all(observers.secondary.as_mut())?;\\n        if ret1 == ret2 {\\n            Ok(ret1)\\n        } else {\\n            // We found a diff in the exit codes!\\n            Ok(ExitKind::Diff {\\n                primary: ret1.into(),\\n                secondary: ret2.into(),\\n            })\\n        }\\n    }\\n}\\n\\n', 'contextualized_content': 'This chunk is part of the `run_target` method implementation in the `DiffExecutor` struct, which executes two wrapped executors sequentially with the same input, compares their exit results, and identifies any differences in their behavior.'}}\n",
      "CompletionUsage(completion_tokens=53, prompt_tokens=2563, total_tokens=2616, prompt_tokens_details={'cached_tokens': 2432}, completion_tokens_details={'reasoning_tokens': 0})\n",
      "{'text_to_embed': '/// Proxy the observers of the inner executors\\n#[derive(Serialize, Deserialize, Debug)]\\n#[serde(\\n    bound = \"A: serde::Serialize + serde::de::DeserializeOwned, B: serde::Serialize + serde::de::DeserializeOwned, DOT: serde::Serialize + serde::de::DeserializeOwned\"\\n)]\\npub struct ProxyObserversTuple<A, B, DOT> {\\n    primary: OwnedMutPtr<A>,\\n    secondary: OwnedMutPtr<B>,\\n    differential: DOT,\\n}\\n\\nimpl<A, B, DOT, S> ObserversTuple<S> for ProxyObserversTuple<A, B, DOT>\\nwhere\\n    A: ObserversTuple<S>,\\n    B: ObserversTuple<S>,\\n    DOT: DifferentialObserversTuple<A, B, S>,\\n    S: UsesInput,\\n{\\n    fn pre_exec_all(&mut self, state: &mut S, input: &S::Input) -> Result<(), Error> {\\n        self.differential.pre_exec_all(state, input)\\n    }\\n\\n\\n\\nThe chunk defines the `ProxyObserversTuple` struct and its implementation for the `ObserversTuple` trait, which acts as a proxy for observers in differential fuzzing executors, facilitating the execution and observation of inputs across primary and secondary executors.', 'metadata': {'doc_id': 'doc_1', 'original_uuid': '5e4c01057a10732d34784af2a97bee9d173863f043b9901de8ef7f57bc590145', 'chunk_id': 'doc_1_chunk_5', 'original_index': 5, 'original_content': '/// Proxy the observers of the inner executors\\n#[derive(Serialize, Deserialize, Debug)]\\n#[serde(\\n    bound = \"A: serde::Serialize + serde::de::DeserializeOwned, B: serde::Serialize + serde::de::DeserializeOwned, DOT: serde::Serialize + serde::de::DeserializeOwned\"\\n)]\\npub struct ProxyObserversTuple<A, B, DOT> {\\n    primary: OwnedMutPtr<A>,\\n    secondary: OwnedMutPtr<B>,\\n    differential: DOT,\\n}\\n\\nimpl<A, B, DOT, S> ObserversTuple<S> for ProxyObserversTuple<A, B, DOT>\\nwhere\\n    A: ObserversTuple<S>,\\n    B: ObserversTuple<S>,\\n    DOT: DifferentialObserversTuple<A, B, S>,\\n    S: UsesInput,\\n{\\n    fn pre_exec_all(&mut self, state: &mut S, input: &S::Input) -> Result<(), Error> {\\n        self.differential.pre_exec_all(state, input)\\n    }\\n\\n', 'contextualized_content': 'The chunk defines the `ProxyObserversTuple` struct and its implementation for the `ObserversTuple` trait, which acts as a proxy for observers in differential fuzzing executors, facilitating the execution and observation of inputs across primary and secondary executors.'}}\n",
      "CompletionUsage(completion_tokens=53, prompt_tokens=2526, total_tokens=2579, prompt_tokens_details={'cached_tokens': 2304}, completion_tokens_details={'reasoning_tokens': 0})\n",
      "{'text_to_embed': '    fn post_exec_all(\\n        &mut self,\\n        state: &mut S,\\n        input: &S::Input,\\n        exit_kind: &ExitKind,\\n    ) -> Result<(), Error> {\\n        self.differential.post_exec_all(state, input, exit_kind)\\n    }\\n\\n    fn pre_exec_child_all(&mut self, state: &mut S, input: &S::Input) -> Result<(), Error> {\\n        self.differential.pre_exec_child_all(state, input)\\n    }\\n\\n    fn post_exec_child_all(\\n        &mut self,\\n        state: &mut S,\\n        input: &S::Input,\\n        exit_kind: &ExitKind,\\n    ) -> Result<(), Error> {\\n        self.differential\\n            .post_exec_child_all(state, input, exit_kind)\\n    }\\n\\n\\n\\nThe chunk is part of the `ProxyObserversTuple` implementation, which defines methods for executing and observing the state and input during differential fuzzing. It focuses on post-execution and child execution phases, delegating these tasks to the differential observers.', 'metadata': {'doc_id': 'doc_1', 'original_uuid': '5e4c01057a10732d34784af2a97bee9d173863f043b9901de8ef7f57bc590145', 'chunk_id': 'doc_1_chunk_6', 'original_index': 6, 'original_content': '    fn post_exec_all(\\n        &mut self,\\n        state: &mut S,\\n        input: &S::Input,\\n        exit_kind: &ExitKind,\\n    ) -> Result<(), Error> {\\n        self.differential.post_exec_all(state, input, exit_kind)\\n    }\\n\\n    fn pre_exec_child_all(&mut self, state: &mut S, input: &S::Input) -> Result<(), Error> {\\n        self.differential.pre_exec_child_all(state, input)\\n    }\\n\\n    fn post_exec_child_all(\\n        &mut self,\\n        state: &mut S,\\n        input: &S::Input,\\n        exit_kind: &ExitKind,\\n    ) -> Result<(), Error> {\\n        self.differential\\n            .post_exec_child_all(state, input, exit_kind)\\n    }\\n\\n', 'contextualized_content': 'The chunk is part of the `ProxyObserversTuple` implementation, which defines methods for executing and observing the state and input during differential fuzzing. It focuses on post-execution and child execution phases, delegating these tasks to the differential observers.'}}\n",
      "CompletionUsage(completion_tokens=50, prompt_tokens=2466, total_tokens=2516, prompt_tokens_details={'cached_tokens': 2176}, completion_tokens_details={'reasoning_tokens': 0})\n",
      "{'text_to_embed': '    /// Returns true if a `stdout` observer was added to the list\\n    #[inline]\\n    fn observes_stdout(&self) -> bool {\\n        self.primary.as_ref().observes_stdout() || self.secondary.as_ref().observes_stdout()\\n    }\\n    /// Returns true if a `stderr` observer was added to the list\\n    #[inline]\\n    fn observes_stderr(&self) -> bool {\\n        self.primary.as_ref().observes_stderr() || self.secondary.as_ref().observes_stderr()\\n    }\\n\\n\\n\\nThe chunk is part of the `ProxyObserversTuple` implementation, providing methods to check if `stdout` or `stderr` observers are present in the list, within the context of differential fuzzing using a `DiffExecutor`.', 'metadata': {'doc_id': 'doc_1', 'original_uuid': '5e4c01057a10732d34784af2a97bee9d173863f043b9901de8ef7f57bc590145', 'chunk_id': 'doc_1_chunk_7', 'original_index': 7, 'original_content': '    /// Returns true if a `stdout` observer was added to the list\\n    #[inline]\\n    fn observes_stdout(&self) -> bool {\\n        self.primary.as_ref().observes_stdout() || self.secondary.as_ref().observes_stdout()\\n    }\\n    /// Returns true if a `stderr` observer was added to the list\\n    #[inline]\\n    fn observes_stderr(&self) -> bool {\\n        self.primary.as_ref().observes_stderr() || self.secondary.as_ref().observes_stderr()\\n    }\\n\\n', 'contextualized_content': 'The chunk is part of the `ProxyObserversTuple` implementation, providing methods to check if `stdout` or `stderr` observers are present in the list, within the context of differential fuzzing using a `DiffExecutor`.'}}\n",
      "CompletionUsage(completion_tokens=51, prompt_tokens=2470, total_tokens=2521, prompt_tokens_details={'cached_tokens': 2304}, completion_tokens_details={'reasoning_tokens': 0})\n",
      "{'text_to_embed': '    /// Runs `observe_stdout` for all stdout observers in the list\\n    fn observe_stdout(&mut self, stdout: &[u8]) {\\n        self.primary.as_mut().observe_stderr(stdout);\\n        self.secondary.as_mut().observe_stderr(stdout);\\n    }\\n\\n    /// Runs `observe_stderr` for all stderr observers in the list\\n    fn observe_stderr(&mut self, stderr: &[u8]) {\\n        self.primary.as_mut().observe_stderr(stderr);\\n        self.secondary.as_mut().observe_stderr(stderr);\\n    }\\n}\\n\\n\\n\\nThe chunk defines methods for observing standard output and error streams within a `ProxyObserversTuple` struct, which is part of a differential fuzzing executor system. These methods ensure that both primary and secondary observers process the output and error data.', 'metadata': {'doc_id': 'doc_1', 'original_uuid': '5e4c01057a10732d34784af2a97bee9d173863f043b9901de8ef7f57bc590145', 'chunk_id': 'doc_1_chunk_8', 'original_index': 8, 'original_content': '    /// Runs `observe_stdout` for all stdout observers in the list\\n    fn observe_stdout(&mut self, stdout: &[u8]) {\\n        self.primary.as_mut().observe_stderr(stdout);\\n        self.secondary.as_mut().observe_stderr(stdout);\\n    }\\n\\n    /// Runs `observe_stderr` for all stderr observers in the list\\n    fn observe_stderr(&mut self, stderr: &[u8]) {\\n        self.primary.as_mut().observe_stderr(stderr);\\n        self.secondary.as_mut().observe_stderr(stderr);\\n    }\\n}\\n\\n', 'contextualized_content': 'The chunk defines methods for observing standard output and error streams within a `ProxyObserversTuple` struct, which is part of a differential fuzzing executor system. These methods ensure that both primary and secondary observers process the output and error data.'}}\n",
      "CompletionUsage(completion_tokens=38, prompt_tokens=2585, total_tokens=2623, prompt_tokens_details={'cached_tokens': 2432}, completion_tokens_details={'reasoning_tokens': 0})\n",
      "{'text_to_embed': 'impl<A, B, DOT> MatchName for ProxyObserversTuple<A, B, DOT>\\nwhere\\n    A: MatchName,\\n    B: MatchName,\\n    DOT: MatchName,\\n{\\n    fn match_name<T>(&self, name: &str) -> Option<&T> {\\n        if let Some(t) = self.primary.as_ref().match_name::<T>(name) {\\n            Some(t)\\n        } else if let Some(t) = self.secondary.as_ref().match_name::<T>(name) {\\n            Some(t)\\n        } else {\\n            self.differential.match_name::<T>(name)\\n        }\\n    }\\n    fn match_name_mut<T>(&mut self, name: &str) -> Option<&mut T> {\\n        if let Some(t) = self.primary.as_mut().match_name_mut::<T>(name) {\\n            Some(t)\\n        } else if let Some(t) = self.secondary.as_mut().match_name_mut::<T>(name) {\\n            Some(t)\\n        } else {\\n            self.differential.match_name_mut::<T>(name)\\n        }\\n    }\\n}\\n\\n\\n\\nThe chunk defines the `MatchName` trait implementation for the `ProxyObserversTuple` struct, enabling it to match names across its primary, secondary, and differential observers.', 'metadata': {'doc_id': 'doc_1', 'original_uuid': '5e4c01057a10732d34784af2a97bee9d173863f043b9901de8ef7f57bc590145', 'chunk_id': 'doc_1_chunk_9', 'original_index': 9, 'original_content': 'impl<A, B, DOT> MatchName for ProxyObserversTuple<A, B, DOT>\\nwhere\\n    A: MatchName,\\n    B: MatchName,\\n    DOT: MatchName,\\n{\\n    fn match_name<T>(&self, name: &str) -> Option<&T> {\\n        if let Some(t) = self.primary.as_ref().match_name::<T>(name) {\\n            Some(t)\\n        } else if let Some(t) = self.secondary.as_ref().match_name::<T>(name) {\\n            Some(t)\\n        } else {\\n            self.differential.match_name::<T>(name)\\n        }\\n    }\\n    fn match_name_mut<T>(&mut self, name: &str) -> Option<&mut T> {\\n        if let Some(t) = self.primary.as_mut().match_name_mut::<T>(name) {\\n            Some(t)\\n        } else if let Some(t) = self.secondary.as_mut().match_name_mut::<T>(name) {\\n            Some(t)\\n        } else {\\n            self.differential.match_name_mut::<T>(name)\\n        }\\n    }\\n}\\n\\n', 'contextualized_content': 'The chunk defines the `MatchName` trait implementation for the `ProxyObserversTuple` struct, enabling it to match names across its primary, secondary, and differential observers.'}}\n",
      "CompletionUsage(completion_tokens=65, prompt_tokens=2608, total_tokens=2673, prompt_tokens_details={'cached_tokens': 0}, completion_tokens_details={'reasoning_tokens': 0})\n",
      "{'text_to_embed': 'impl<A, B, DOT> ProxyObserversTuple<A, B, DOT> {\\n    fn set(&mut self, primary: &A, secondary: &B) {\\n        self.primary = OwnedMutPtr::Ptr(ptr::from_ref(primary) as *mut A);\\n        self.secondary = OwnedMutPtr::Ptr(ptr::from_ref(secondary) as *mut B);\\n    }\\n}\\n\\nimpl<A, B, OTA, OTB, DOT> UsesObservers for DiffExecutor<A, B, OTA, OTB, DOT>\\nwhere\\n    A: HasObservers<Observers = OTA>,\\n    B: HasObservers<Observers = OTB, State = A::State>,\\n    OTA: ObserversTuple<A::State>,\\n    OTB: ObserversTuple<A::State>,\\n    DOT: DifferentialObserversTuple<OTA, OTB, A::State>,\\n{\\n    type Observers = ProxyObserversTuple<OTA, OTB, DOT>;\\n}\\n\\nimpl<A, B, OTA, OTB, DOT> UsesState for DiffExecutor<A, B, OTA, OTB, DOT>\\nwhere\\n    A: UsesState,\\n    B: UsesState<State = A::State>,\\n{\\n    type State = A::State;\\n}\\n\\n\\n\\nThe chunk provides implementations for the `ProxyObserversTuple` and `DiffExecutor` structs, focusing on setting observer pointers and defining associated types for observers and state. It is part of a larger document detailing a differential fuzzing executor that runs two executors with the same input to identify differences in their behavior.', 'metadata': {'doc_id': 'doc_1', 'original_uuid': '5e4c01057a10732d34784af2a97bee9d173863f043b9901de8ef7f57bc590145', 'chunk_id': 'doc_1_chunk_10', 'original_index': 10, 'original_content': 'impl<A, B, DOT> ProxyObserversTuple<A, B, DOT> {\\n    fn set(&mut self, primary: &A, secondary: &B) {\\n        self.primary = OwnedMutPtr::Ptr(ptr::from_ref(primary) as *mut A);\\n        self.secondary = OwnedMutPtr::Ptr(ptr::from_ref(secondary) as *mut B);\\n    }\\n}\\n\\nimpl<A, B, OTA, OTB, DOT> UsesObservers for DiffExecutor<A, B, OTA, OTB, DOT>\\nwhere\\n    A: HasObservers<Observers = OTA>,\\n    B: HasObservers<Observers = OTB, State = A::State>,\\n    OTA: ObserversTuple<A::State>,\\n    OTB: ObserversTuple<A::State>,\\n    DOT: DifferentialObserversTuple<OTA, OTB, A::State>,\\n{\\n    type Observers = ProxyObserversTuple<OTA, OTB, DOT>;\\n}\\n\\nimpl<A, B, OTA, OTB, DOT> UsesState for DiffExecutor<A, B, OTA, OTB, DOT>\\nwhere\\n    A: UsesState,\\n    B: UsesState<State = A::State>,\\n{\\n    type State = A::State;\\n}\\n\\n', 'contextualized_content': 'The chunk provides implementations for the `ProxyObserversTuple` and `DiffExecutor` structs, focusing on setting observer pointers and defining associated types for observers and state. It is part of a larger document detailing a differential fuzzing executor that runs two executors with the same input to identify differences in their behavior.'}}\n",
      "CompletionUsage(completion_tokens=49, prompt_tokens=2528, total_tokens=2577, prompt_tokens_details={'cached_tokens': 2304}, completion_tokens_details={'reasoning_tokens': 0})\n",
      "{'text_to_embed': 'impl<A, B, OTA, OTB, DOT> HasObservers for DiffExecutor<A, B, OTA, OTB, DOT>\\nwhere\\n    A: HasObservers<Observers = OTA>,\\n    B: HasObservers<Observers = OTB, State = A::State>,\\n    OTA: ObserversTuple<A::State>,\\n    OTB: ObserversTuple<A::State>,\\n    DOT: DifferentialObserversTuple<OTA, OTB, A::State>,\\n{\\n    #[inline]\\n    fn observers(&self) -> &ProxyObserversTuple<OTA, OTB, DOT> {\\n        unsafe {\\n            self.observers\\n                .get()\\n                .as_mut()\\n                .unwrap()\\n                .set(self.primary.observers(), self.secondary.observers());\\n            self.observers.get().as_ref().unwrap()\\n        }\\n    }\\n\\n\\n\\nThis chunk defines the implementation of the `HasObservers` trait for the `DiffExecutor` struct, which manages the observers for both primary and secondary executors, ensuring they are correctly set and retrieved during differential fuzzing operations.', 'metadata': {'doc_id': 'doc_1', 'original_uuid': '5e4c01057a10732d34784af2a97bee9d173863f043b9901de8ef7f57bc590145', 'chunk_id': 'doc_1_chunk_11', 'original_index': 11, 'original_content': 'impl<A, B, OTA, OTB, DOT> HasObservers for DiffExecutor<A, B, OTA, OTB, DOT>\\nwhere\\n    A: HasObservers<Observers = OTA>,\\n    B: HasObservers<Observers = OTB, State = A::State>,\\n    OTA: ObserversTuple<A::State>,\\n    OTB: ObserversTuple<A::State>,\\n    DOT: DifferentialObserversTuple<OTA, OTB, A::State>,\\n{\\n    #[inline]\\n    fn observers(&self) -> &ProxyObserversTuple<OTA, OTB, DOT> {\\n        unsafe {\\n            self.observers\\n                .get()\\n                .as_mut()\\n                .unwrap()\\n                .set(self.primary.observers(), self.secondary.observers());\\n            self.observers.get().as_ref().unwrap()\\n        }\\n    }\\n\\n', 'contextualized_content': 'This chunk defines the implementation of the `HasObservers` trait for the `DiffExecutor` struct, which manages the observers for both primary and secondary executors, ensuring they are correctly set and retrieved during differential fuzzing operations.'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  50%|█████     | 1/2 [00:21<00:21, 21.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletionUsage(completion_tokens=43, prompt_tokens=2436, total_tokens=2479, prompt_tokens_details={'cached_tokens': 2304}, completion_tokens_details={'reasoning_tokens': 0})\n",
      "{'text_to_embed': '    #[inline]\\n    fn observers_mut(&mut self) -> &mut ProxyObserversTuple<OTA, OTB, DOT> {\\n        unsafe {\\n            self.observers\\n                .get()\\n                .as_mut()\\n                .unwrap()\\n                .set(self.primary.observers(), self.secondary.observers());\\n            self.observers.get().as_mut().unwrap()\\n        }\\n    }\\n}\\n\\n\\nThe chunk is a method implementation within the `DiffExecutor` struct, which provides mutable access to the proxy observers, ensuring they are updated with the current observers from the primary and secondary executors.', 'metadata': {'doc_id': 'doc_1', 'original_uuid': '5e4c01057a10732d34784af2a97bee9d173863f043b9901de8ef7f57bc590145', 'chunk_id': 'doc_1_chunk_12', 'original_index': 12, 'original_content': '    #[inline]\\n    fn observers_mut(&mut self) -> &mut ProxyObserversTuple<OTA, OTB, DOT> {\\n        unsafe {\\n            self.observers\\n                .get()\\n                .as_mut()\\n                .unwrap()\\n                .set(self.primary.observers(), self.secondary.observers());\\n            self.observers.get().as_mut().unwrap()\\n        }\\n    }\\n}\\n', 'contextualized_content': 'The chunk is a method implementation within the `DiffExecutor` struct, which provides mutable access to the proxy observers, ensuring they are updated with the current observers from the primary and secondary executors.'}}\n",
      "CompletionUsage(completion_tokens=87, prompt_tokens=1540, total_tokens=1627, prompt_tokens_details={'cached_tokens': 1408}, completion_tokens_details={'reasoning_tokens': 0})\n",
      "{'text_to_embed': '#[cfg(windows)]\\nuse std::ptr::write_volatile;\\nuse std::{path::PathBuf, ptr::write};\\n\\n#[cfg(feature = \"tui\")]\\nuse libafl::monitors::tui::{ui::TuiUI, TuiMonitor};\\n#[cfg(not(feature = \"tui\"))]\\nuse libafl::monitors::SimpleMonitor;\\nuse libafl::{\\n    corpus::{InMemoryCorpus, OnDiskCorpus},\\n    events::SimpleEventManager,\\n    executors::{inprocess::InProcessExecutor, ExitKind},\\n    feedbacks::{CrashFeedback, MaxMapFeedback},\\n    fuzzer::{Fuzzer, StdFuzzer},\\n    inputs::{BytesInput, HasTargetBytes},\\n    mutators::{StdScheduledMutator, StringCategoryRandMutator, StringSubcategoryRandMutator},\\n    observers::StdMapObserver,\\n    schedulers::QueueScheduler,\\n    stages::{mutational::StdMutationalStage, StringIdentificationStage},\\n    state::StdState,\\n    Evaluator,\\n};\\nuse libafl_bolts::{current_nanos, rands::StdRand, tuples::tuple_list, AsSlice};\\n\\n\\n\\nThis chunk is part of a Rust program that sets up a fuzzing environment using the libafl library. It includes conditional imports for Windows and TUI features, and imports various components from libafl for corpus management, event handling, execution, feedback, fuzzing, input handling, mutation, observation, scheduling, and state management. The chunk is foundational for initializing the fuzzing framework and configuring its components.', 'metadata': {'doc_id': 'doc_2', 'original_uuid': '78cd6ead8e87695b47c2904e3027ae2b7251677caa5c5815b38c8756fe1a0b0c', 'chunk_id': 'doc_2_chunk_0', 'original_index': 0, 'original_content': '#[cfg(windows)]\\nuse std::ptr::write_volatile;\\nuse std::{path::PathBuf, ptr::write};\\n\\n#[cfg(feature = \"tui\")]\\nuse libafl::monitors::tui::{ui::TuiUI, TuiMonitor};\\n#[cfg(not(feature = \"tui\"))]\\nuse libafl::monitors::SimpleMonitor;\\nuse libafl::{\\n    corpus::{InMemoryCorpus, OnDiskCorpus},\\n    events::SimpleEventManager,\\n    executors::{inprocess::InProcessExecutor, ExitKind},\\n    feedbacks::{CrashFeedback, MaxMapFeedback},\\n    fuzzer::{Fuzzer, StdFuzzer},\\n    inputs::{BytesInput, HasTargetBytes},\\n    mutators::{StdScheduledMutator, StringCategoryRandMutator, StringSubcategoryRandMutator},\\n    observers::StdMapObserver,\\n    schedulers::QueueScheduler,\\n    stages::{mutational::StdMutationalStage, StringIdentificationStage},\\n    state::StdState,\\n    Evaluator,\\n};\\nuse libafl_bolts::{current_nanos, rands::StdRand, tuples::tuple_list, AsSlice};\\n\\n', 'contextualized_content': 'This chunk is part of a Rust program that sets up a fuzzing environment using the libafl library. It includes conditional imports for Windows and TUI features, and imports various components from libafl for corpus management, event handling, execution, feedback, fuzzing, input handling, mutation, observation, scheduling, and state management. The chunk is foundational for initializing the fuzzing framework and configuring its components.'}}\n",
      "CompletionUsage(completion_tokens=88, prompt_tokens=1526, total_tokens=1614, prompt_tokens_details={'cached_tokens': 1408}, completion_tokens_details={'reasoning_tokens': 0})\n",
      "{'text_to_embed': '/// Coverage map with explicit assignments due to the lack of instrumentation\\nstatic mut SIGNALS: [u8; 64] = [0; 64];\\nstatic mut SIGNALS_PTR: *mut u8 = unsafe { SIGNALS.as_mut_ptr() };\\n\\n/// Assign a signal to the signals map\\nfn signals_set(idx: usize) {\\n    unsafe { write(SIGNALS_PTR.add(idx), 1) };\\n}\\n\\n#[allow(clippy::similar_names, clippy::manual_assert)]\\npub fn main() {\\n    // The closure that we want to fuzz\\n    let mut harness = |input: &BytesInput| {\\n        let target = input.target_bytes();\\n        let buf = target.as_slice();\\n        let goal = b\"abcdefghijklmnopqrstuvwxyzabcdefghijklmnopqrstuvwxyz\";\\n        let mut i = 0;\\n        for _ in buf.iter().zip(goal).take_while(|(b, c)| b == c) {\\n            signals_set(i);\\n            i += 1;\\n        }\\n        if i == goal.len() {\\n            #[cfg(unix)]\\n            panic!(\"Artificial bug triggered =)\");\\n\\n\\n\\nThis chunk is part of a Rust program that sets up a fuzzing environment using the libafl library. It defines a coverage map and a function to set signals, which are used in a fuzzing harness to test inputs against a specific goal string. The chunk includes the main function where the fuzzing logic is implemented, including the setup of a closure to be fuzzed and the handling of a potential bug trigger.', 'metadata': {'doc_id': 'doc_2', 'original_uuid': '78cd6ead8e87695b47c2904e3027ae2b7251677caa5c5815b38c8756fe1a0b0c', 'chunk_id': 'doc_2_chunk_1', 'original_index': 1, 'original_content': '/// Coverage map with explicit assignments due to the lack of instrumentation\\nstatic mut SIGNALS: [u8; 64] = [0; 64];\\nstatic mut SIGNALS_PTR: *mut u8 = unsafe { SIGNALS.as_mut_ptr() };\\n\\n/// Assign a signal to the signals map\\nfn signals_set(idx: usize) {\\n    unsafe { write(SIGNALS_PTR.add(idx), 1) };\\n}\\n\\n#[allow(clippy::similar_names, clippy::manual_assert)]\\npub fn main() {\\n    // The closure that we want to fuzz\\n    let mut harness = |input: &BytesInput| {\\n        let target = input.target_bytes();\\n        let buf = target.as_slice();\\n        let goal = b\"abcdefghijklmnopqrstuvwxyzabcdefghijklmnopqrstuvwxyz\";\\n        let mut i = 0;\\n        for _ in buf.iter().zip(goal).take_while(|(b, c)| b == c) {\\n            signals_set(i);\\n            i += 1;\\n        }\\n        if i == goal.len() {\\n            #[cfg(unix)]\\n            panic!(\"Artificial bug triggered =)\");\\n\\n', 'contextualized_content': 'This chunk is part of a Rust program that sets up a fuzzing environment using the libafl library. It defines a coverage map and a function to set signals, which are used in a fuzzing harness to test inputs against a specific goal string. The chunk includes the main function where the fuzzing logic is implemented, including the setup of a closure to be fuzzed and the handling of a potential bug trigger.'}}\n",
      "CompletionUsage(completion_tokens=66, prompt_tokens=1428, total_tokens=1494, prompt_tokens_details={'cached_tokens': 1280}, completion_tokens_details={'reasoning_tokens': 0})\n",
      "{'text_to_embed': '            #[cfg(windows)]\\n            unsafe {\\n                write_volatile(0 as *mut u32, 0);\\n            }\\n        }\\n        ExitKind::Ok\\n    };\\n\\n    // Create an observation channel using the signals map\\n    let observer = unsafe { StdMapObserver::from_mut_ptr(\"signals\", SIGNALS_PTR, SIGNALS.len()) };\\n\\n    // Feedback to rate the interestingness of an input\\n    let mut feedback = MaxMapFeedback::new(&observer);\\n\\n    // A feedback to choose if an input is a solution or not\\n    let mut objective = CrashFeedback::new();\\n\\n\\n\\nThis chunk is part of a Rust-based fuzzing setup using the libafl library, specifically within the main function where it defines the behavior of the fuzzing harness. It includes a conditional block for Windows systems to trigger an artificial bug and sets up feedback mechanisms for evaluating input interestingness and identifying crash solutions.', 'metadata': {'doc_id': 'doc_2', 'original_uuid': '78cd6ead8e87695b47c2904e3027ae2b7251677caa5c5815b38c8756fe1a0b0c', 'chunk_id': 'doc_2_chunk_2', 'original_index': 2, 'original_content': '            #[cfg(windows)]\\n            unsafe {\\n                write_volatile(0 as *mut u32, 0);\\n            }\\n        }\\n        ExitKind::Ok\\n    };\\n\\n    // Create an observation channel using the signals map\\n    let observer = unsafe { StdMapObserver::from_mut_ptr(\"signals\", SIGNALS_PTR, SIGNALS.len()) };\\n\\n    // Feedback to rate the interestingness of an input\\n    let mut feedback = MaxMapFeedback::new(&observer);\\n\\n    // A feedback to choose if an input is a solution or not\\n    let mut objective = CrashFeedback::new();\\n\\n', 'contextualized_content': 'This chunk is part of a Rust-based fuzzing setup using the libafl library, specifically within the main function where it defines the behavior of the fuzzing harness. It includes a conditional block for Windows systems to trigger an artificial bug and sets up feedback mechanisms for evaluating input interestingness and identifying crash solutions.'}}\n",
      "CompletionUsage(completion_tokens=48, prompt_tokens=1456, total_tokens=1504, prompt_tokens_details={'cached_tokens': 1280}, completion_tokens_details={'reasoning_tokens': 0})\n",
      "{'text_to_embed': '    // create a State from scratch\\n    let mut state = StdState::new(\\n        // RNG\\n        StdRand::with_seed(current_nanos()),\\n        // Corpus that will be evolved, we keep it in memory for performance\\n        InMemoryCorpus::new(),\\n        // Corpus in which we store solutions (crashes in this example),\\n        // on disk so the user can get them after stopping the fuzzer\\n        OnDiskCorpus::new(PathBuf::from(\"./crashes\")).unwrap(),\\n        // States of the feedbacks.\\n        // The feedbacks can report the data that should persist in the State.\\n        &mut feedback,\\n        // Same for objective feedbacks\\n        &mut objective,\\n    )\\n    .unwrap();\\n\\n\\n\\nThis chunk initializes a new state for the fuzzer, setting up the random number generator, in-memory and on-disk corpora, and feedback states, which are essential for managing the fuzzing process and storing results.', 'metadata': {'doc_id': 'doc_2', 'original_uuid': '78cd6ead8e87695b47c2904e3027ae2b7251677caa5c5815b38c8756fe1a0b0c', 'chunk_id': 'doc_2_chunk_3', 'original_index': 3, 'original_content': '    // create a State from scratch\\n    let mut state = StdState::new(\\n        // RNG\\n        StdRand::with_seed(current_nanos()),\\n        // Corpus that will be evolved, we keep it in memory for performance\\n        InMemoryCorpus::new(),\\n        // Corpus in which we store solutions (crashes in this example),\\n        // on disk so the user can get them after stopping the fuzzer\\n        OnDiskCorpus::new(PathBuf::from(\"./crashes\")).unwrap(),\\n        // States of the feedbacks.\\n        // The feedbacks can report the data that should persist in the State.\\n        &mut feedback,\\n        // Same for objective feedbacks\\n        &mut objective,\\n    )\\n    .unwrap();\\n\\n', 'contextualized_content': 'This chunk initializes a new state for the fuzzer, setting up the random number generator, in-memory and on-disk corpora, and feedback states, which are essential for managing the fuzzing process and storing results.'}}\n",
      "CompletionUsage(completion_tokens=102, prompt_tokens=1508, total_tokens=1610, prompt_tokens_details={'cached_tokens': 0}, completion_tokens_details={'reasoning_tokens': 0})\n",
      "{'text_to_embed': '    // The Monitor trait define how the fuzzer stats are displayed to the user\\n    #[cfg(not(feature = \"tui\"))]\\n    let mon = SimpleMonitor::new(|s| println!(\"{s}\"));\\n    #[cfg(feature = \"tui\")]\\n    let ui = TuiUI::with_version(String::from(\"Baby Fuzzer\"), String::from(\"0.0.1\"), false);\\n    #[cfg(feature = \"tui\")]\\n    let mon = TuiMonitor::new(ui);\\n\\n    // The event manager handle the various events generated during the fuzzing loop\\n    // such as the notification of the addition of a new item to the corpus\\n    let mut mgr = SimpleEventManager::new(mon);\\n\\n    // A queue policy to get testcasess from the corpus\\n    let scheduler = QueueScheduler::new();\\n\\n    // A fuzzer with feedbacks and a corpus scheduler\\n    let mut fuzzer = StdFuzzer::new(scheduler, feedback, objective);\\n\\n\\n\\nThis chunk is part of a Rust-based fuzzing setup using the libafl library. It describes the configuration of the monitoring and event management components, as well as the initialization of the fuzzer and its scheduling policy. The code is conditional on whether a text-based user interface (TUI) feature is enabled, affecting how fuzzer statistics are displayed. The chunk is situated within the main function, which orchestrates the fuzzing process, including setting up the executor and mutational stages.', 'metadata': {'doc_id': 'doc_2', 'original_uuid': '78cd6ead8e87695b47c2904e3027ae2b7251677caa5c5815b38c8756fe1a0b0c', 'chunk_id': 'doc_2_chunk_4', 'original_index': 4, 'original_content': '    // The Monitor trait define how the fuzzer stats are displayed to the user\\n    #[cfg(not(feature = \"tui\"))]\\n    let mon = SimpleMonitor::new(|s| println!(\"{s}\"));\\n    #[cfg(feature = \"tui\")]\\n    let ui = TuiUI::with_version(String::from(\"Baby Fuzzer\"), String::from(\"0.0.1\"), false);\\n    #[cfg(feature = \"tui\")]\\n    let mon = TuiMonitor::new(ui);\\n\\n    // The event manager handle the various events generated during the fuzzing loop\\n    // such as the notification of the addition of a new item to the corpus\\n    let mut mgr = SimpleEventManager::new(mon);\\n\\n    // A queue policy to get testcasess from the corpus\\n    let scheduler = QueueScheduler::new();\\n\\n    // A fuzzer with feedbacks and a corpus scheduler\\n    let mut fuzzer = StdFuzzer::new(scheduler, feedback, objective);\\n\\n', 'contextualized_content': 'This chunk is part of a Rust-based fuzzing setup using the libafl library. It describes the configuration of the monitoring and event management components, as well as the initialization of the fuzzer and its scheduling policy. The code is conditional on whether a text-based user interface (TUI) feature is enabled, affecting how fuzzer statistics are displayed. The chunk is situated within the main function, which orchestrates the fuzzing process, including setting up the executor and mutational stages.'}}\n",
      "CompletionUsage(completion_tokens=83, prompt_tokens=1419, total_tokens=1502, prompt_tokens_details={'cached_tokens': 1280}, completion_tokens_details={'reasoning_tokens': 0})\n",
      "{'text_to_embed': '    // Create the executor for an in-process function with just one observer\\n    let mut executor = InProcessExecutor::new(\\n        &mut harness,\\n        tuple_list!(observer),\\n        &mut fuzzer,\\n        &mut state,\\n        &mut mgr,\\n    )\\n    .expect(\"Failed to create the Executor\");\\n\\n    // Generate 8 initial inputs\\n    fuzzer\\n        .evaluate_input(\\n            &mut state,\\n            &mut executor,\\n            &mut mgr,\\n            BytesInput::new(vec![b\\'a\\']),\\n        )\\n        .unwrap();\\n\\n\\n\\nThis chunk is part of a Rust-based fuzzing setup using the libafl library. It details the creation of an in-process executor for a fuzzing harness and the evaluation of initial inputs to kickstart the fuzzing process. The executor is responsible for executing the fuzzing target with the provided inputs and observing the results, while the fuzzer evaluates these inputs to identify potential vulnerabilities or crashes.', 'metadata': {'doc_id': 'doc_2', 'original_uuid': '78cd6ead8e87695b47c2904e3027ae2b7251677caa5c5815b38c8756fe1a0b0c', 'chunk_id': 'doc_2_chunk_5', 'original_index': 5, 'original_content': '    // Create the executor for an in-process function with just one observer\\n    let mut executor = InProcessExecutor::new(\\n        &mut harness,\\n        tuple_list!(observer),\\n        &mut fuzzer,\\n        &mut state,\\n        &mut mgr,\\n    )\\n    .expect(\"Failed to create the Executor\");\\n\\n    // Generate 8 initial inputs\\n    fuzzer\\n        .evaluate_input(\\n            &mut state,\\n            &mut executor,\\n            &mut mgr,\\n            BytesInput::new(vec![b\\'a\\']),\\n        )\\n        .unwrap();\\n\\n', 'contextualized_content': 'This chunk is part of a Rust-based fuzzing setup using the libafl library. It details the creation of an in-process executor for a fuzzing harness and the evaluation of initial inputs to kickstart the fuzzing process. The executor is responsible for executing the fuzzing target with the provided inputs and observing the results, while the fuzzer evaluates these inputs to identify potential vulnerabilities or crashes.'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents: 100%|██████████| 2/2 [00:32<00:00, 16.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletionUsage(completion_tokens=54, prompt_tokens=1440, total_tokens=1494, prompt_tokens_details={'cached_tokens': 1024}, completion_tokens_details={'reasoning_tokens': 0})\n",
      "{'text_to_embed': '    // Setup a mutational stage with a basic bytes mutator\\n    let mutator = StdScheduledMutator::new(tuple_list!(\\n        StringCategoryRandMutator,\\n        StringSubcategoryRandMutator,\\n        StringSubcategoryRandMutator,\\n        StringSubcategoryRandMutator,\\n        StringSubcategoryRandMutator\\n    ));\\n    let mut stages = tuple_list!(\\n        StringIdentificationStage::new(),\\n        StdMutationalStage::transforming(mutator)\\n    );\\n\\n    fuzzer\\n        .fuzz_loop(&mut stages, &mut executor, &mut state, &mut mgr)\\n        .expect(\"Error in the fuzzing loop\");\\n}\\n\\n\\nThis chunk describes the setup of a mutational stage in a fuzzing process using the libafl library. It involves creating a mutator with various string mutation strategies and integrating it into the fuzzing loop to transform inputs during the fuzzing process.', 'metadata': {'doc_id': 'doc_2', 'original_uuid': '78cd6ead8e87695b47c2904e3027ae2b7251677caa5c5815b38c8756fe1a0b0c', 'chunk_id': 'doc_2_chunk_6', 'original_index': 6, 'original_content': '    // Setup a mutational stage with a basic bytes mutator\\n    let mutator = StdScheduledMutator::new(tuple_list!(\\n        StringCategoryRandMutator,\\n        StringSubcategoryRandMutator,\\n        StringSubcategoryRandMutator,\\n        StringSubcategoryRandMutator,\\n        StringSubcategoryRandMutator\\n    ));\\n    let mut stages = tuple_list!(\\n        StringIdentificationStage::new(),\\n        StdMutationalStage::transforming(mutator)\\n    );\\n\\n    fuzzer\\n        .fuzz_loop(&mut stages, &mut executor, &mut state, &mut mgr)\\n        .expect(\"Error in the fuzzing loop\");\\n}\\n', 'contextualized_content': 'This chunk describes the setup of a mutational stage in a fuzzing process using the libafl library. It involves creating a mutator with various string mutation strategies and integrating it into the fuzzing loop to transform inputs during the fuzzing process.'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contextual Vector database loaded and saved. Total chunks processed: 20\n",
      "Total input tokens without caching: 8145\n",
      "Total output tokens: 1182\n",
      "Total input tokens read from cache: 35072\n",
      "Total input token savings from prompt caching: 78.99% of all input tokens used were read from cache.\n"
     ]
    }
   ],
   "source": [
    "# Load the transformed dataset\n",
    "with open('data/codebase_chunks.json', 'r') as f:\n",
    "    transformed_dataset = json.load(f)\n",
    "\n",
    "# Initialize the ContextualVectorDB\n",
    "contextual_db = ContextualVectorDB(\"my_contextual_db\")\n",
    "\n",
    "# Load and process the data\n",
    "#note: consider increasing the number of parallel threads to run this faster, or reducing the number of parallel threads if concerned about hitting your API rate limit\n",
    "await contextual_db.load_data(transformed_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
